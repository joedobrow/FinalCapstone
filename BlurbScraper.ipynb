{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This notebook scrapes a popular book website for 'blurbs' by iterating through the titles\n",
    "# in the books table from book-crossings\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import scrapy\n",
    "from scrapy.crawler import CrawlerProcess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "b'Skipping line 6452: expected 8 fields, saw 9\\nSkipping line 43667: expected 8 fields, saw 10\\nSkipping line 51751: expected 8 fields, saw 9\\n'\n",
      "b'Skipping line 92038: expected 8 fields, saw 9\\nSkipping line 104319: expected 8 fields, saw 9\\nSkipping line 121768: expected 8 fields, saw 9\\n'\n",
      "b'Skipping line 144058: expected 8 fields, saw 9\\nSkipping line 150789: expected 8 fields, saw 9\\nSkipping line 157128: expected 8 fields, saw 9\\nSkipping line 180189: expected 8 fields, saw 9\\nSkipping line 185738: expected 8 fields, saw 9\\n'\n",
      "b'Skipping line 209388: expected 8 fields, saw 9\\nSkipping line 220626: expected 8 fields, saw 9\\nSkipping line 227933: expected 8 fields, saw 11\\nSkipping line 228957: expected 8 fields, saw 10\\nSkipping line 245933: expected 8 fields, saw 9\\nSkipping line 251296: expected 8 fields, saw 9\\nSkipping line 259941: expected 8 fields, saw 9\\nSkipping line 261529: expected 8 fields, saw 9\\n'\n",
      "/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3049: DtypeWarning: Columns (3) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "#BookCrossing\n",
    "df_books = pd.read_csv('/Data Science/BX-CSV-Dump/BX-Books.csv', sep=';', error_bad_lines=False, encoding = \"latin-1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The website I am scraping has a consistent URL pattern that I exploit so that I can iterate through my dataset of books. 'starts' is a list of search query URLs for each book, and I feed this list into my scraper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_scrape = list(df_books.ISBN)\n",
    "starts = []\n",
    "for isbn in to_scrape:\n",
    "    starts.append('https://www.goodreads.com/search?q=' + isbn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Along with scraping the text of the 'blurb', I scrape the final URL. I cannot simply use the list of books in the dataset and line it up with scraped results due to heavy loss in the iteration of this algorithm. By scraping the URL along with blurb I will be able to match up the scraped blurbs with the right books."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scrapy\n",
    "from scrapy.crawler import CrawlerProcess\n",
    "\n",
    "class ESSpider(scrapy.Spider):\n",
    "    name = \"ESS\"\n",
    "    start_urls = starts\n",
    "\n",
    "    def parse(self, response):\n",
    "        for article in response.xpath('//html'):\n",
    "            \n",
    "                yield {\n",
    "                    'text': article.xpath('body/div[@class=\"content\"]/div[@class=\"mainContentContainer \"]/div[@class=\"mainContent \"]/div[@class=\"mainContentFloat \"]/div[@class=\"leftContainer\"]/div[@id=\"topcol\"]/div[@id=\"metacol\"]/div[@id=\"descriptionContainer\"]//span/text()').extract(),\n",
    "                    'URL' : response.url,\n",
    "                }\n",
    "process = CrawlerProcess({\n",
    "    'FEED_FORMAT': 'csv',\n",
    "    'FEED_URI': 'blurbs2.csv', \n",
    "    'LOG_ENABLED': False,   \n",
    "    'ROBOTSTXT_OBEY': True,\n",
    "    'USER_AGENT': 'Joe Dobrow jdobrow@gmail.com',\n",
    "    'AUTOTHROTTLE_ENABLED': True,\n",
    "    'HTTPCACHE_ENABLED': True,\n",
    "    'DOWNLOAD_DELAY' : .25\n",
    "})\n",
    "\n",
    "process.crawl(ESSpider)\n",
    "process.start()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
